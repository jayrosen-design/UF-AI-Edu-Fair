[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15529285.svg)](https://doi.org/10.5281/zenodo.15529285)

# AI & AR In the Classroom: Developing the Future of Learning

This presentation, "AI & AR In the Classroom: Developing the Future of Learning," was delivered by Jay Rosen at the AI in Education Fair hosted by the UF College of Education on May 20, 2025. More information about the event can be found at https://education.ufl.edu/ai/ai-in-education-fair/. This document provides a slide-by-slide overview of the presentation content. This presentation explores the intersection of Artificial Intelligence (AI) and Augmented Reality (AR) in K-12 education, showcasing how AI tools accelerate the development of immersive learning experiences. It uses the "New Worlds Reading AR Expeditions" game as a case study.

Slide deck: https://docs.google.com/presentation/d/1djiTHjXI8RfHJpULen8nshJPZrw6H6j3jBkYQCVJvsU/edit?usp=sharing


## Presentation Overview

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_01.png?raw=true)

* **UF COLLEGE OF EDUCATION**
* **AI & AR In the Classroom**
* **Developing the Future of Learning**
* **Jay Rosen**
* AI in Education Fair 2025 – UF College of Education
* Session: AI & AR in the Classroom - Developing the Future of Learning
* Presenter: Jay Rosen
* Explore the dynamic intersection of Artificial Intelligence and Augmented Reality in K-12 education.
* This 30-minute breakout session reveals how AI tools are accelerating the development of immersive learning experiences, using the “New Worlds Reading AR Expeditions” game as a live case study.
* Discover how AI assists in every phase, from brainstorming concepts (with tools like ChatGPT and Miro) and creating assets like concept art and animated 3D models (DALL-E, Luma Labs Genie, Mixamo), and music with SUNO, to programming dynamic AI creature behaviors and ensuring AR elements realistically integrate into the user’s environment.
* We will share practical AI strategies and demonstrate adaptable tools for K-12 educators and administrators.
* Learn how AI assistants like Gemini or Copilot can help draft lesson plans, how image generators create custom visuals, and how AI supports accessibility through translation.
* Ideal for educators, administrators, and curriculum specialists, this session features an AR game demo and provides actionable insights into leveraging AI for enhanced student engagement and innovative, immersive teaching methods.

---

## Presenting Today

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_02.png?raw=true)

* **Jay Rosen**
* Application Programmer II
* UF College of Education
* jayrosen@ufl.edu

Hello, I’m Jay Rosen, an App Developer at the College of Education in the E-Learning, Technology, and Communications Department. Today, I’m going to share how we are transforming literacy education by merging Augmented Reality with Artificial Intelligence, with our new App - New Worlds Reading AR Expeditions, an educational software that creates engaging, immersive experiences for 3rd to 5th graders, by bringing books to life
In this presentation, I’m going to go over:
* An Overview of AR & VR in Education, what the future of learning looks like with these new technologies
* We will dive into New Worlds Reading AR Expeditions,
* Go behind the scenes for the app was developed with various AI tools, you can potentially integrate into your own workflow or classroom.
* Depending on the time, I’ll share some additional resources for getting more value out of the chatbots - and choosing the right AI for you and your students.

---

## AR & VR in Education

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_03.png?raw=true)

---

## Augmented Reality (AR)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_04.png?raw=true)

* Alters but does not completely replace how you perceive the world around you.
* It overlays digital information onto your real-world view.
* **Immersion:** Partial
* **Technology:** Smartphones, tablets, AR glasses.
* **Examples:**
    * Pokémon GO
    * Amazon's Product Viewer
* Augmented Reality is best suited for contextualization and visualization

---

## Virtual Reality (VR)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_05.png?raw=true)

* Replaces how you see the world around you, creating a simulated environment.
* **Immersion:** Total
* **Technology:** Head Mounted Displays (Meta Quest, HTC Vive)
* **Examples:**
    * Beat Saber (rhythm game)
    * Meta Horizon (Metaverse)
    * Meta Horizon Workrooms
* Virtual Reality is best suited for simulation and experiential immersion

---

## AI in Augmented Reality

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_06.png?raw=true)

* **Challenge:** Ensuring smooth placement, interaction, and tracking of digital objects in real-world AR environments.
* **AI-Enhanced Solutions:**
    * ARCore & ARKit provided real-time surface detection and object anchoring for seamless AR integration.
    * Niantic Spatial Platform enabled advanced spatial mapping and segmentation for immersive experience.
* Unity AR Foundation integrates ARCore (Android) and ARKit (IOS) libraries to leverage device hardware for precise plane detection and occlusion.
* In the interior AR scene (left), the virtual aquarium anchors coral and seaweed to detected planes, providing a dynamic environment for fish to navigate.
* In the outdoor AR scene (right), a grassy area transforms into an interactive pond, inviting players to fish.
* The Augmented Reality itself leverages AI for real-time surface detection and object anchoring, making 3D models appear grounded in the user's space with proper lighting and shadows.
* We used the same Niantic technology that created the game, Pokémon Go, using device specific tools from Apple and Google which were key to achieving this real-world integration.

---

## AR & VR Benefits

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_07.png?raw=true)

* **Accelerated Learning & Confidence**
    * VR training can be up to 4x faster than traditional methods, boosting learner confidence by as much as 275%.
    * 275% more confident to act on what they learned after training
    * 4x faster than classroom training on average
    * 4x more focused than e-learners
    * 3.75x more emotionally connected to the content than classroom learners
* [1] Virtual Speech. "Benefits of VR for Developing Soft Skills". https://virtualspeech.com/blog/benefits-vr-soft-skills-training
* According to studies from Virtual Speech - AR & VR provide benefits such as Boost to Learning: Learners using VR can be trained up to 4 times faster than traditional classroom methods and show up to a 275% increase in confidence to apply the skills learned.

---

## AR & VR Benefits (Continued)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_08.png?raw=true)

* **Rapid School Adoption**
    * US K-12 school adoption of AR/VR was projected to surge from <20% in 2022 to over 40% by 2024.
* **Massive Market Growth**
    * The global AR/VR education market is forecast to potentially exceed USD 65-80 Billion by the early 2030s.
* The Market will Grow At the CAGR of: 20.26%
* The Forecasted Market Size for 2033 in USD: $75.0 B
* [2] Matsh Youth Development. "Emerging Technologies in Education: Statistics on Al and VR Adoption Rates in 2024". https://www.matsh.co/en/statistics-on-ai-vr-adoption-in-education/
* [3] Market US. "AR and VR in Education Market To Hit USD 75 Billion by 2033" https://scoop.market.us/ar-and-vr-in-education-market-news/
* Market Research shows growing Massive Market Expansion and Rapid School adoption.
* The integration of these technologies is accelerating quickly; for instance, projections indicated that over 40% of K-12 schools in the US would incorporate AR/VR by 2024, more than doubling the adoption rate from less than 20% in 2022.
* The global AR and VR in the education market is experiencing explosive growth, with forecasts predicting it could reach values ranging from approximately 65 billion to over 80 Billion Dollars by the early 2030s, showcasing massive investment and expected adoption (exact figures vary by report).

---

## AR & VR Benefits (Continued)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_09.png?raw=true)

* **Time to complete training** (Source PwC VR Soft Skills Traning Efficacy Study, 2020)
    * E-learn: 45 minutes
    * Classroom: 2 hours
    * VR: 29 minutes
* **Average emotional connection felt to learning content** (Source: PwC VR Soft Skills training Efficacy Study, 2020)
* [4] Virtual Speech. "VR Stats for the Training & Education Industry in 2025". https://virtualspeech.com/blog/vr-stats-training-education
* Lastly, this study from PWC Soft Skills Training shows that AR/VR training can allow learners to complete training faster. In this study, the training session, VR lesson, took 29 minutes to complete, while E-learning took 45 minutes, and traditional Classroom training took 2 hours. And the learners felt more emotionally connected to the learning content, as you can see in the bar graph on the right - almost 5x more connected, as the content becomes more personal and immersive.

---

## Why Choose AR/VR in Teaching?

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_10.png?raw=true)

* **"Gamification" Element**
    * Introduces a "fun element" that can capture and maintain attention, especially crucial for younger learners or complex topics.
    * Echoes social situations for younger generation
    * Transforms learning from passive consumption to active participation.
* **Improved Immersion and Learning**
    * Provides realistic, repeatable practice for skills in fields like medicine or technical training without real-world risks or high costs.
    * Allows for trial-and-error learning in a controlled environment (e.g., surgical simulations, emergency response drills).
    * Creates memorable, context-rich learning opportunities that go beyond textbooks or videos.
    * Visualizing complex concepts in 3D or interacting directly with subject matter can lead to deeper understanding and better knowledge retention compared to abstract explanations.
* **Accessibility**
    * Allows students to experience environments or scenarios otherwise impossible or impractical (e.g., exploring the human body, visiting historical sites, practicing complex procedures).
    * Ability to conceptualize abstract principles
* AR/VR is also great for Safe & Cost-Effective Simulation.

---

## AR Expeditions {newworldsreading}

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_11.png?raw=true)

---

## AR Expeditions Partners

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_12.png?raw=true)

* EQUITABLE LEARNING TECHNOLOGY LAB
* E-Learning, Technology and Communications
* PK Yonge Developmental Research School at the University of Florida
* UF COLLEGE OF EDUCATION
* UF Lastinger Center for Learning UNIVERSITY of FLORIDA
* Let’s dive into New Worlds Reading AR Expeditions, this is a project being developed here at College of Education, that is transforming literacy education by merging Augmented Reality with Artificial Intelligence.
* Our team at the E-Learning, Technology, and Communication Department is collaborating with the Lastinger Center for Learning, to build new educational software that creates engaging, immersive experiences with literature for 3rd to 5th graders, bringing books to life with the magic of Augmented Reality.
* This app is tied to the Florida state-wide reading program, The New Worlds Reading Initiative

---

## About New Worlds Reading Initiative

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_13.png?raw=true)

* The New Worlds Reading Initiative is a book distribution program in collaboration with Scholastic, particularly for reluctant and struggling readers.
* New Worlds Reading's books and activities support students in:
    * Strengthening literacy skills
    * Building reading confidence
    * Nurturing a lifelong love of reading
* The New Worlds Reading Initiative program provides free books to elementary students across Florida who are reluctant readers or are struggling to read at grade level.
* The Lastinger Center is partnered with Scholastic Books to deliver free books to the homes of these students, so they can read the books with their families.
* This program strengthens literacy skills, builds reading confidence, and nurtures a love of reading.

---

## AR Expeditions: Project Reasoning

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_14.png?raw=true)

* **Problem:** The NWRI program distributes books to families with struggling readers, but how do we encourage them to engage with these books?
* **Solution:** An app that combines the magic of augmented reality with literary games, building upon themes of the NWRI books.
* With this free reading program comes a new problem - although we can provide free books, it doesn’t necessarily mean the books will be read.
* How can we motivate and encourage students to engage with these books?
* How do we get books to be less perceived as a challenge to kids, and more as a new type of "experience" that is built into a game that can help them feel that learning vocabulary can be exciting and rewarding?
* Our solution combines the magic of Augmented Reality with fun games built upon the themes of the books.

---

## AR Expeditions Overview

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_15.png?raw=true)

* Students explore exciting environments, interact with educational content, and foster a love for reading.
* AR Expeditions builds confidence and motivates children to build a deeper connection to literacy.
* **Target Audience:** 3rd - 5th graders
* **Platform:** Smartphones and tablets
* **Game Engine:** Unity & AR Foundation
* Each of the books comes with a QR code, providing free access to download the New Worlds Reading AR Expeditions app for iOS or Android.
* Using a phone or tablet, the app uses Augmented Reality to overlay 3D models spatially around you, bringing the book's themes and characters to life.
* This creates an immersive experience that makes reading feel less like a chore and more like an adventure, an AR Expedition, building confidence and motivation to build a deeper connection to literacy.
* By blending the digital and physical, it sparks curiosity. Imagine reading about the ocean and then seeing a life-size whale swimming above you. That's memorable and makes learning tangible.
* To achieve this, we are using the Unity game engine and AR Foundation toolkit, which is essentially the same spatial computing framework that was used to create the popular game, Pokémon Go.

---

## Ocean Experience

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_16.png?raw=true)

* First of four themes, focusing on the aquatic ecology of Florida.
* Split into "mini-experiences":
    * Aquarium
    * Bubble Pop
    * Coloring
    * Fishing
* The app will feature 4 themed 'Expeditions' based on the topics of the books in the program.
* Our first expedition, launching this Spring, is the 'Ocean Experience, focusing on the aquatic ecology of Florida.
* This theme is inspired by books like the Magic School Bus or Who would Win: Whale vs Giant Squid.
* We have 4 mini-games in the Ocean Experience - Aquarium, Bubble Pop, Fishing, and Coloring–each utilizing Augmented Reality in different ways.

---

## Aquarium

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_17.png?raw=true)

* Build a live ecosystem in your room, and watch animals interact with each other and their environment.
* AR: Additive construction.
* Life size animals swim in the space and plants become rooted to the ground plane.
* When playing, please be aware of your surroundings and supervise any children using the device.
* In 'Aquarium' game mode, the students create their own aquatic ecosystem.
* They can place different sea creatures and watch them swim, eat, and interact realistically, with these behaviors driven by AI game mechanics.
* For example, a small clownfish might eat seaweed, but introduce a shark, and the AI shark will hunt the clownfish, and then the clownish may try to hide in a sea anemone or form a school of fish with others to evade the shark as a group - this all creates a personal, dynamic learning environment.
* Letting children experiment like this turns their world into a playground for learning through curiosity and play.

---

## Bubble Pop

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_18.png?raw=true)

* Pop the bubbles corresponding to correct answers, strengthening your knowledge about florida ecology.
* AR: Bubbles and marine life fill the room. Can walk around to see new viewpoints.
* In 'Bubble Pop', the student answers questions by popping large bubbles that float in the room, which if correctly, will release the life size 3D character such as the Dolphin.
* In the game, you would hear the sound effect of the dolphin and can learn more about the animal or item when completing the level.
* Since the 3D objects stay in place where they are spawned, you can walk around and see the characters and bubbles from different viewpoints.
* There is also a hint system to help teach the word if the student is unfamiliar with the term.

---

## Coloring

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_19.png?raw=true)

* Color in your favorite sea creature, then watch it come to life as a 3D model.
* AR: Animate the student creations, from 2D to 3D.
* The 'Coloring’ mini game lets the students fill in a digital coloring book of marine animals and then uses AR to bring their unique creation to life as a 3D animated object in their space.
* It connects their creativity directly to the AR magic.

---

## Fishing

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_20.png?raw=true)

* Answer vocabulary questions to obtain lures, then use those lures to reel in fish.
* AR: Transform the ground plane into a fishing pond and walk on the wooden dock.
* Our last mini game on this expedition is ‘Fishing'. This game mode transforms the floor around you into a fishing dock with a large pond of water.
* Here, students answer vocabulary prompts related to the books to earn fishing lures.
* They can then use these lures to try and catch the fish in the pond.
* After completing a vocabulary question, they are also given a Deeper Look to reflect and critically think about that word in their own context.
* When a fish is caught it is added to the side of the dock, like displaying a trophy.

---

## AR Expeditions: Impact

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_21.png?raw=true)

* Ongoing research pilot at P.K. Younge Developmental Research School led by doctoral student Irene Kao and supervised by Dr. Nigel Newbutt
* 3rd grade test group found the app exciting and engaging, helped them understand the subject matter of the books
* Publication at The Society for Information Technology and Teacher Education (SITE)
    * "From Participants to Designers: Exploring Self-Efficacy through CoDesigning an Augmented Reality Application in a School"
* Forthcoming publication for IEEE International Conference on Advanced Learning Technologies (ICALT)
    * "Exploring Elementary Students' Perception and Engagement of Reading using an Augmented Reality Educational Technology Application"
* We are currently testing the app with a pilot group of 3rd graders at PK Young, with research led by doctoral student Irene Kao and supervised by Dr. Nigel Newbutt.
* In our preliminary study, the students found the app exciting and engaging and mentioned that it helped them understand the subject matter of the books.
* The research has been published at the SITE Conference in Orlando and will be part of a forthcoming publication at the IEEE conference in Taiwan in July.
* Ultimately, New Worlds Reading AR Expeditions leverages Augmented Reality to tackle the challenge of reading motivation for students who need it most.
* By creating engaging, immersive, and fun experiences directly linked to the books they receive, we aim to build reading confidence, spark genuine curiosity, and foster a deeper, more positive connection to literacy.

---

## The Next Expedition

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_22.png?raw=true)

* We are now working on the 2nd Expedition - based on Graphic Novels and Comic books.
* We are developing a superhero builder, where you can customize your own character with different clothing options, headgear, accessories, and even change your skin tone or clothing color to any color you desire.
* You can even become an Alligator or a Cat with costumes.
* This character customization is like games like Roblox, Fortnight, and The Sims, creating your own avatar identity.
* After creating your character, you will be able to go on your own adventures.
* In this video showing the current in-development game modes and testing out walking around.

---

## Co-Design (Setting)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_23.png?raw=true)

* What setting are you drawn to? Is there a reason why?
* In our Co-Design at PK Young, we are learning from the students what setting they want to explore.
* We have learned they are interested in the high seas pirate ship, the ice caverns, and the moon as potential locations to explore.

---

## Co-Design (Student Illustrations)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_24.png?raw=true)

* These are illustrations from the 3rd grade students at PK Young, creating their own superheroes.
* In the top left is an illustration of a mermaid like character that is exploring the underwater ocean, on the top right and bottom left is a sci-fi scene on the moon with robot army and Space Dog hero who roams the moon going on adventure.
* There is also an ice dragon that a student wanted to rescue in the mountains.

---

## Developing with AI

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_25.png?raw=true)

---

## Developing with AI & Augmented Reality for the Classroom

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_26.png?raw=true)

* **New Worlds Reading AR Expeditions**
* **Abstract:** New Worlds Reading AR Expeditions is an educational Augmented Reality (AR) video game designed to enhance literacy in 3rd to 5th-grade students through interactive, immersive experiences. By integrating AI tools at every stage of development from brainstorming and concept art to programming and gameplay we demonstrate the transformative potential of AI-driven design in educational technologies. AI-enhanced tools powered the rapid generation of creative ideas, streamlined art and music asset creation, automated game scripting, and provided multilingual voiceovers and translations to reach diverse student audiences. Moreover these AI-driven methodologies effectively address common challenges in software and game development, such as overcoming design bottlenecks, reducing resource-intensive asset production, and simplifying complex debugging processes. Dynamic gameplay is supported by AI-driven behavior trees, allowing creatures to exhibit realistic interactions and respond to player decisions. This project exemplifies how the integration of AI and AR technologies can create engaging, personalized learning environments to enhance literacy outcomes through fun games. The collaboration between the UF College of Education and technical teams further underscores the critical role of interdisciplinary innovation in shaping the future of learning
* **Challenges & AI-Enhanced Solutions:**
    * **Ideation & Collaboration:**
        * Challenge: Generating innovative ideas and transforming them into structured game design documents
        * AI-Enhanced Solutions: Miro Al, ChatGPT, Notebook LM (Gemini)
    * **Concept Art:**
        * Challenge: Rapidly producing diverse, high-quality concept art while maintaining design consistency
        * AI-Enhanced Solutions: DALL-E, MidJourney, Adobe Firefly
    * **3D Prototypes:**
        * Challenge: Quickly developing interactive prototypes and generating 3D models for early stage visualization
        * AI-Enhanced Solutions: Lovable, Luma AI, Skybox AI
    * **Audio & Music:**
        * Challenge: Producing custom audio sound effects, background music, and multilingual voiceovers
        * AI-Enhanced Solutions: SUNO, Google Music FX, ElevenLabs
    * **Game Development:**
        * Challenge: Developing debugging, and integrating complex game scripts within the Unity game engine.
        * AI-Enhanced Solutions: NaviGator AI (GPT40), GPT-4 Vision, GitHub Copilot
    * **Augmented Reality:**
        * Challenge: Ensuring smooth placement, interaction, and tracking of digital objects in real-world AR environments
        * AI-Enhanced Solutions: ARCore, ARKit, Niantic Spatial Platform
    * **AI Gameplay:**
        * Challenge: Designing dynamic, interactive gameplay where AI-controlled characters react to players and environment.
        * AI-Enhanced Solutions: Unity ML Agents, OPSIVE Behavior Trees, LLOMA3 (exploratory)
    * **Multi-Language Support:**
        * Challenge: Producing custom audio sound effects, background music, and multilingual voiceovers (Note: This challenge description seems duplicated from Audio & Music, likely meant to be "Providing accurate translations...")
        * AI-Enhanced Solutions: Google Translate, Meta Seamless M4T & Recognissimo (exploratory)
* Earlier this year, I presented this science poster at both the AI Summit in Orlando and the UF Education Research Symposium.
* Since creating this poster, there are some newer AI tools I will also share, since this space is constantly evolving.

---

## Brainstorming

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_27.png?raw=true)

* **Challenge:** Generating innovative ideas and transforming them into structured game design documents.
* **AI-Enhanced Solutions:**
    * Miro Al organized brainstorming sessions more efficiently with Al generated sticky notes.
    * ChatGPT expanded rough ideas into well-defined gameplay mechanics, narrative, and design elements.
    * Notebook LM (Gemini) compiled game design content into a shared, interactive knowledge base.
* For Ideation & Collaboration, tools like Miro AI and ChatGPT helped us brainstorm, turning rough ideas into structure game mechanics.

---

## Generative Art

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_28.png?raw=true)

* **Challenge:** Rapidly producing diverse, high-quality concept art while maintaining design consistency.
* **AI-Enhanced Solutions:**
    * DALL-E and MidJourney produced hundreds of art concepts from descriptive prompts, allowing fast exploration of different themes.
    * Adobe Firefly polished and refined visuals, removing defects from the AI-generated images.
* Even as a trained artist, generating diverse visuals quickly is still tough. AI tools like DALL-E and Midjourney generated hundreds of concept arts. This allowed us to iterate and visualize how game ideas may appear in Mixed Reality, which is essential for this new type of e-learning software development.

---

## Generative Art (Newer AI Solutions)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_29.png?raw=true)

* **Newer AI-Enhanced Solutions:**
    * Google Gemini Imagen3 & Whisk provide more control to adjust and modify the AI image by providing Subject, Scene, Style.
    * Capable of generating video clips from the image.
* Whisk is a newer AI image generator from Gemini, using Imagen3.

---

## Generative Art (ChatGPT 4o)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_30.png?raw=true)

* **Newer AI-Enhanced Solutions:**
    * GPT 4o image generation within ChatGPT creating images that retain resemblance and style.
    * Improved letters and graphic logos.
    * Upload a picture, and request to make it in a different style.
        * In the style of Studio Ghibli
        * Muppets Style
        * As an 80's action figure with accessories
* Of course, there is a big update from ChatGPT 2 months ago, that let everyone turn themselves into Studio Ghibli anime character or Muppets. This update to ChatGPT 4o omni model integrated image generation directly into it, instead of using Dall-e which is just retained on image and text, the omni model is more capable of thinking, and can produce much higher quality images of different styles. There is also improved text into images, so you can read the words and create logos.

---

## Developing Storyboards

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_31.png?raw=true)

* Upload a picture of the character as a reference and provide some background about the story.
* Mention the expected style of art and target audience.
* **Prompts to create these images in ChatGPT:**
    * Create a 4 panel comic strip of story.
    * Create a comic book cover for this story.
    * Create an image of this as an AR / Mixed Reality game commercial.
* This is how I’m using the latest ChatGPT image generation to help develop our Superhero adventure game. I will use a single chat GPT conversation window describing the general story, and background, and use the image generation to create images based on the story ideas.

---

## Developing Characters

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_32.png?raw=true)

* Upload a picture or image generated by ChatGPT.
* Describe what they are wearing, what they are doing, where they are, who they are with.
* Extract the character from this image, and place on a white background for a character sheet
* To develop characters, upload a picture or image generated by ChatGPT. Describe what they are wearing, what they are doing, where they are, and who they are with. Extract the character from this image, and place it on a white background for a character sheet

---

## Audio & Music

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_33.png?raw=true)

* **Challenge:** Producing custom audio sound effects, background music, and multilingual voiceovers.
* **AI-Enhanced Solutions:**
    * SUNO and Google Music FX generated looping instrumental tracks, ambient sounds, and custom music aligned with the game's underwater theme.
    * ElevenLabs created custom life-like voiceovers for the game narrator.
* Custom Audio & Music are vital for immersion. Multi-Language Support is crucial for accessibility. We're using tools like Google Translate and Meta M4T to support English, Spanish, and Haitian Creole localizations.

---

## Music (SUNO Examples)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_34.png?raw=true)

* SUNO generated music soundtracks of various genres developed for the Graphic Novel Expedition.
* Each thematic album adds to the immersion of the AR experience and storytelling.
* Genres include: Synth-Pop, Ambient EDM, Renaissance Folk, Sea Shanty Orchestral, Super Hero Cinematic
* Suno had a major update recently that made it even better at creating music, and mixing genres. These are some examples of the thematic soundtrack albums I’m creating for the hero adventure games, from Synth-Pop and Ambient music in outerspace, to Renaisaance Folk on the Ice Dragon Adventure, to Sea shanties while exploring the high seas, and of course cinematic orchestral songs to accompany a superhero movie.

---

## Music Generation with ChatGPT & SUNO

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_35.png?raw=true)

* Using ChatGPT to generate SUNO prompts based on game themes and concept art.
* Example prompt generation for "High Seas Pirate Adventure" and "Legend of the Ice Dragon".
* This is example of creating the music with ChatGPT - I describe the genre of music and upload some concept art, and it generates prompts that I can use in suno for several songs that tie together to form a soundtrack.

---

## SUNO Interface

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_36.png?raw=true)

* SUNO interface showing generated songs like "Ballad of the Snow-Top Quest" with lyrics and style descriptions.
* This is Suno, I copy and paste the song style description, and the lyrics if it has that. Next, I’ll share the samples of the music generated while going over AI Video.

---

## AI Video

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_37.png?raw=true)

* **Challenge:** Generating animations to convey storytelling.
* **AI-Enhanced Solutions:**
    * Higgsfield creates video clips using a start and end frame. Library of SFX and types of camera shots.
    * Gemini VEO 2 creates video clips from a text prompt (with Gemini Pro), and with Image prompt (with Whisk)
* AI videos are also now being explored, with tools like Higgsfield and Gemini Veo.

---

## Higgsfield - AI Video Generation

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_38.png?raw=true)

* Higgsfield interface for Text to Image and Image to Video generation.
* Prompt example: "In a sunlit classroom, a magical book lies open on a desk, its pages alive with vibrant illustrations of a knight and a dragon leaping forth. The Steadicam glides gracefully behind them, catching papers suspended"
* This is higgsfield - start end frame, and an example of single image. For start and end frame, it generates all the images in between these sequences and creates its own story.

---

## Storyboard to Video

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_39.png?raw=true)

* Example of taking concept art images and creating a fuller sequence, like an animation.
* Since all the videos generated are only 5-8 seconds long, you piece them together in apps like Adobe Premiere or Clip Champ, or Final Cut.
*(Visual example of a 3rd-grade storyboard transformed into a video sequence)*

---

## AI Video Landscape is Evolving

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_40.png?raw=true)

* Logos of various AI video generation tools: sora, KlingAl, LUMA AI, runway, synthesia, Pika

---

## 3D Prototypes

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_41.png?raw=true)

* **Challenge:** Quickly developing interactive prototypes and generating 3D models for early-stage visualization.
* **AI-Enhanced Solutions:**
    * Lovable created functional prototypes for AR demos and research tools with minimal coding.
    * Luma AI generated NeRF-based, textured 3D models from descriptive prompts. (Outputs were sufficient for prototyping but not production quality)
    * Skybox AI provided 360-degree HDR backgrounds that simulated underwater game environments.
    * Hugging Face an exploratory playground for AI apps.
* For 3D Prototypes, creating models and environments can be slow and resource intensive. Loveable enabled rapid prototyping with a No Code Tool, Luma AI Genie generated 3D models from text prompts, and Skybox AI created immersive 360 backgrounds, which was valuable in the early stages of designing our virtual ocean theme game.

---

## Lovable (GPT Engineer)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_42.png?raw=true)

* Free & Paid tier
* Generate an entire app from prompt or image upload
* They host the app and sync to GitHub
* Website: https://gptengineer.app/

---

## Lovable - New Worlds Reading (Analytics Dashboard Example)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_43.png?raw=true)

* Built app in a day
* Example: NWR Analytics Dashboard (https://nwr-analytics.gptengineer.run/)

---

## Lovable - Hero Prototype (Character Customization Example)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_44.png?raw=true)

* Built app in a day
* Example: Hero Platformer Character Customization

---

## Game Development (Coding & Debugging)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_45.png?raw=true)

* **Challenge:** Developing, debugging, and integrating complex game scripts within the Unity game engine.
* **AI-Enhanced Solutions:**
    * NaviGatorAI (GPT40) assisted in generating C# scripts, accelerating the development of gameplay elements.
    * GPT-4 Vision can interpret screen captures of the game to help debug issues with Unity and scripts.
    * GitHub Copilot provided real-time code completion and error detection, streamlining the coding process.
* In Game Development, coding complexity and debugging are major hurdles. NaviGator AI chatbots from OpenAI and Anthropic Claude and GitHub Copilot assisted with C# code generation and programming, and GPT-4 Vision even helped us visually debug the game within Unity by interpreting screen captures to walkthrough problems and help fix them.

---

## GitHub Copilot

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_46.png?raw=true)

* GitHub Pro & GitHub Copilot are free for EDU accounts
* Puts GPT 4o directly in Visual Studio Code
* Explain code and help write new code
* Website: https://github.com/features/copilot

---

## AI Gameplay

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_47.png?raw=true)

* **Challenge:** Designing dynamic, interactive gameplay where AI-controlled characters react to players and environment.
* **AI-Enhanced Solutions:**
    * Unity ML Agents & OPSIVE Behavior Trees define decision-making pathways, allowing AI characters to respond to stimuli and adapt to changing in-game conditions.
    * Adobe Mixamo animates the custom 3D characters from library of animations.
    * LLAMA (exploratory) is being evaluated for AI-driven conversations to further personalize learning and offer custom challenges.
* Our AI Gameplay uses Unity ML Agents and Behavior Trees allows characters, like fish, to react dynamically to their environment and stimuli. For example, in our aquarium mode, a small clownfish might eat seaweed, but introduce a shark, and the AI dictates that the shark will hunt the clownfish – creating a dynamic mini-ecosystem. Letting children experiment like this turns their world into a playground for learning through curiosity and play
* Looking ahead with AI-driven gameplay, I’m exploring the possibility of embedding Meta’s LLaMA3 AI Model directly into the game engine, for personalized AI conversations and procedural challenges based on a student's detected reading level or playstyle. Imagine the game adjusting difficulty or generating new levels tailored specifically to the individual learner.

---

## Mixamo Character Animations

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_48.png?raw=true)

* Adobe Mixamo interface for adding animations to characters.
* This is Adobe Mixamo - adding animations to our characters with AI.

---

## Multi-Language Support

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_49.png?raw=true)

* **Challenge:** Providing accurate translations and interactive voice support without compromising storage or performance.
* **AI-Enhanced Solutions:**
    * Google Translate generated initial text translations, providing a foundation for further linguistic refinement.
    * Meta Seamless M4T (exploratory) is under evaluation for real-time text and audio translation.
* The language selection screen allows players to configure the game's language using Google Translate, exemplified here by the Spanish version of the Bubble Pop game mode.

---

## AI Tools Summary (February 2025)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_50.png?raw=true)

* **Brainstorming:** Miro, Figma, OpenAI, Gemini
* **Concept Art:** DALL-E, Adobe Firefly, Midjourney
* **3D Game Assets:** LUMA AI, Skybox AI, mixamo, NVIDIA
* **Project Summaries:** NotebookLM, Gemini, OpenAI
* **Code Generation:** NaviGatorAI, GitHub Copilot, OpenAI, Claude, Bezi
* **Prototype:** lovable, Hugging Face
* **Music Generation:** SUNO, LABS.GOOGLE
* **Text to Speech / Speech to Text:** ElevenLabs, Whisper, Recognissino
* **Translations:** Google Translate, SEAMLESS M4T
* **Augmented Reality:** ARCore, ARKit, NIANTIC SPATIAL PLATFORM, Meta
* **AI Gameplay:** Unity Llama 3, OPSIVE
* **Data Analysis:** pandas, python, OpenAI, OpenCV
* This is a breakdown of the AI tools I’ve been using in my process (February 2025). And already this list is outdated and is missing the AI Video category. (May 2025)

---

## AI For Your Classroom

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_51.png?raw=true)

---

## UF NaviGator Chat

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_52.png?raw=true)

* **UF Information Technology NaviGator Chat**
* NaviGator AI allows you to use different Large Language Models (LLMs) with your own dataset. You can use AI to discover trends and patterns, look for insights, and produce reports based on your data.
* Launch NaviGator Chat / NaviGator Chat Getting Started

---

## NaviGator Chat User Guide

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_53.png?raw=true)

* Link: https://assets.webadmin.ufl.edu/navigator/navigator-chat-user-guide/scormcontent/index.html#/
* This guide is your key to mastering NaviGator Chat, providing access to a variety of advanced Al models from OpenAI, Google, Meta, Claude, and more.
* Topics range from the basics of logging in to advanced subjects such as Prompt Engineering and Custom Instructions, which help you tailor Al outputs to meet your specific needs.
* Whether you're just getting started or have experience with other Large Language Models (LLMs), this guide will equip you with the knowledge to maximize your use of NaviGator Chat.
* Dive in and start from the beginning by clicking on 'START COURSE' or select a topic to jump straight to a specific section.
* There is a Navigator Chat user guide available as well, It’s at the bottom of the Navigator page - The User Guide goes over how to use the Navigator, different use cases, examples, and also the data policies.

---

## Data Policies (NaviGator Chat)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_54.png?raw=true)

* Currently, NaviGator Chat is approved for use with **OPEN DATA** only. It has not yet been approved for use with SENSITIVE or RESTRICTED DATA.
* **OPEN DATA examples:** Advertisements, Job postings, Published research, UF catalogs, UF regulations and policies, Press releases, UF directory
* **SENSITIVE DATA examples:** Employee data, Exams, Unpublished research, System security plans
* **RESTRICTED DATA examples:** Student records, PHI (Protected Health Information), PII (Personally Identifiable Information), Card holder data, Examination and assessment instruments
* For more information on data classification, visit Data Classification Guidelines.
* Although Navigator Chat is a more secure chatbot environment that is hosted by UF, The Data Policies for Navigator chat approve the use with OPEN DATA only. Navigator chat is not yet approved to use Sensitive or Restricted Data. This policy also applies to using non-UF AI chatbots like ChatGPT and Gemini, so please do not use any Sensitive or Restricted data with AI tools. Although unpublished research data is listed as sensitive, Navigator and LLMS can absolutely help you with your research.

---

## NaviGator Chat Interface

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_55.png?raw=true)

* NaviGator Chat interface showing model selection (e.g., gemini-2.5-pro-exp), chat history, and input field.
* Here I’m logged into Navigator Chat. To select the AI model, there is a drop down at the top, and on the right sidebar if you have that open. You can search by name or scroll through the list.

---

## Available Language Models in NaviGator Chat

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_56.png?raw=true)

* Language Models and Hosting:
    * **UF HiPerGator:** llama-3.1-70b-instruct, llama-3.1-8b-instruct, mistral-7b-instruct, nim-mistral-7b-instruct, nim-llama-3.1-nemotron-nano-8B-v1, nim-llama-3.1-8b-instruct, mixtral-8x7b-instruct, codestral-22b, granite-3.1-8b, gemma-3-27b-it, Stable Diffusion (image generator)
    * **Microsoft Azure:** gpt-4.1-mini, gpt-4.1-nano, gpt-4.1, o4-mini, o4-mini-medium, o4-mini-high, o3-mini, o3-mini-medium, o3-mini-high, o1-mini, gpt-4o, gpt-4o-mini, gpt-3.5-turbo, DALL-E-3 (image generator)
    * **Google:** gemini-2.5-pro-exp, gemini-2.5-flash-exp, gemini-2.0-flash, gemini-1.5-flash, gemini-1.5-pro
    * **Amazon Web Services:** command-r-plus, command-r, claude-3.7-sonnet, claude-3.5-sonnet-v2, claude-3.5-sonnet, claude-3.5-haiku, claude-3-haiku, claude-3-sonnet, claude-3-opus, mistral-large, nova-micro, nova-lite, nova-pro
* These are the current LLMS hosted on Navigator, including open source models running on HiPerGator, the OpenAI ChatGPT and Dall-e Image Generator running on Microsoft Azure, the Google Gemini models, and the AWS Claude models. Each LLM does have different characteristics since they are trained on different data sets, so I will try to go over some of the more useful LLMs of the bunch. At this time, these LLMs do not search online, compared to if you purchased the premium model of like Gemini or ChatGPT - however, that feature might come in a future update.

---

## Which AI is Best? Chatbot Arena LLM Leaderboard

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_57.png?raw=true)

* **Chatbot Arena LLM Leaderboard:** Crowd-sourced AI benchmarking platform where users rank AI models.
* Top ranked models include Gemini-2.5-Pro, GPT-4o, Grok 3, DeepSeek-V3, etc. (Rankings as of a certain date, likely to change)
* Website: https://lmarena.ai/
* So, with all these AI models - which AI is best? It’s a difficult answer, since each AI is trained on different data. You can look at the Chatbot Arena LLM Leaderboard, which is crowd-sourced AI benchmarking for each of the models in tasks such as writing, math, coding, creative writing, and more criteria. The AI LLM landscape is constantly changing, just this past month, all the top 10 models have been completely re-arranged with new releases.

---

## Which AI is Best? Chatbot Arena Overview (Task-Specific Rankings)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_58.png?raw=true)

* Chatbot Arena Overview shows model rankings across various tasks: Overall, Hard Prompts, Coding, Math, Creative Writing, Instruction Following, Longer Query, Multi-Turn.
* Website: https://lmarena.ai/

---

## Best AI for the Task: Prompt-to-Leaderboard (P2L)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_59.png?raw=true)

* Prompt-to-Leaderboard (P2L) showcases AI model performance in specific categories.
* Interactive explorer for leaderboards across broad and specific categories.
* Allows highlighting a model's strengths and weaknesses.
* Website: https://lmarena.ai/
* Prompt to Leaderboard is another way to analyze which AI Model performs specifically well at a type of category. Each of these categories and topics can be drilled down further, where you do see certain AI models perform better or worse - which could help you if you choose the right AI model for the type of tasks or research you want to complete.

---

## Comparison of NaviGator LLMs: Pricing and Capabilities

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_60.png?raw=true)

* Table comparing models like GPT-4o, GPT-4.1, Gemini 2.5 Pro, Claude 3.5/3.7 Sonnet, Llama 3.1 70B, Codestral-22b based on:
    * Training Data Cutoff
    * Context Window (tokens)
    * Max Output Length (tokens)
    * Input Price / 1M Tokens
    * Output Price / 1M Tokens
* This table provides a comparison of various AI language models based on their training data cutoff, context window size, maximum output length, and token pricing.
* The Training Data Cutoff indicates how current the knowledge is.
* Context window or tokens is the maximum number of tokens or words the model can process at once. This is essentially the amount of memory that the AI can hold. If it seems to have forgotten basic info in a long conversation, it's because it has gone past its maximum context window.
* The models with the highest Context window include Gemini 1.5 pro and Gemini 1.5 flash. Newer ChatGPT O3 mini and Claude Sonnet have about double the context window compared to some other models.
* The Max Output length is the longest possible response. This is great for fully articulated long responses, achievable with models like ChatGPT o3-mini (approx. 100,000 tokens, or 200-300 book pages / 2,000 lines of code). GPT 4o has about 16,000 tokens output (approx. 40-page book / 300 lines of code).
* For pricing, GPT 4o costs about $5 for every 1 million input tokens and $15 for every 1 million output tokens. The university is covering the cost of these models.

---

## NavigatorAI™ Recommendations

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_61.png?raw=true)

* **For Largest context window and deep research, working with code, large datasets, or long documents:** use Gemini 2.5 Pro or GPT-4.1 (Word doc also mentions Gemini 1.5 pro or Claude 3.5 sonnet and o3-mini or the o1-mini for code/large datasets)
* **For balance of speed, reasoning, and accuracy:** use GPT 4o or Claude 3.7 (Word doc also lists GPT 4o)
* **For lower cost open-source:** use LLama or Codestral

---

## AI for Work (Prompt Generation Website)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_62.png?raw=true)

* **AI for Work:** A website with ChatGPT prompts to get work done.
* Select Your Department (e.g., Real Estate, Human Resources, Legal, Retail, Education, Engineering, etc.)
* Website: https://www.aiforwork.co/
* AI For Work is a Prompt Generating website that can help you find a persona, and provides you with starter prompts to help you complete your task or think about how AI can be used in your field. From the AI for Work homepage, we see a bunch of different careers. I’m going to select Education.

---

## AI for Work (Education Department)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_63.png?raw=true)

* **Department: Education** - to provide learning opportunities and facilitate the acquisition of knowledge and skills for individuals within the organization.
* Select Your Role (e.g., Teacher, Curriculum Developer, Professor, Tutor)
* The most advanced ChatGPT prompt and resource library with custom GPTs and helpful resources, designed for professionals
* Under Education, it narrows down to different roles. For this example I’m going to select Professor.

---

## AI for Work (Professor Prompts)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_64.png?raw=true)

* **Role: Professor** - Select a prompt:
    * Consult An Expert: Professor
    * Create A Grant Proposal
    * Create A Student Progress Report
    * And many more...
* Under Professor, we now see simple prompt starters that give us idea of how we can use AI to accomplish a task such as Creating a Grant Proposal or creating a conference Abstract Document.

---

## AI for Work (Example: Create A Grant Proposal Prompt)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_65.png?raw=true)

* Detailed prompt structure for "Create A Grant Proposal" for a Professor in Education.
    * Includes persona definition, task description, success factors, rules for interaction, evaluation rubric, and revision process.
* When you select one of the starter prompts, you will see a much larger prompt that you can copy and paste into the Navigator or ChatGPT.

---

## Persona Pattern (AI for Work in NaviGator Chat)

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_66.png?raw=true)

* Example of pasting the AI for Work "Create a Grant Proposal" prompt into NaviGator Chat.
* NaviGator Chat understands the persona and asks clarifying questions to tailor the proposal.
* So here I am back in Navigator, and I passed the prompt. You will notice that the Navigator understands the pre-written prompt and introduces itself as the expert professor at grant writing. It then gives you list of 5 questions to fill out to gather more context and understanding about your specific request.
* As you provide additional context for the AI for work bot, it is programmed to ask more questions to refine its output, even using a rubric to grade its own output to improve the outcome. So even if you can’t come up with an advanced prompt yourself, you can easily copy and paste one of the AI for Work prompts to get you started and have the AI help guide you in providing the context for it to work more effectively.

---

## CO-STAR Framework for Effective Prompts

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_67.png?raw=true)

* **CO-STAR Framework:** A structured approach for creating effective prompts. The more of these you incorporate, the better your results.
    * **Context:** Providing background information helps the LLM understand the specific scenario.
    * **Objective:** Clearly defining the task directs the LLM's focus.
    * **Style:** Specifying the desired writing style aligns the LLM response.
    * **Tone:** Setting the tone ensures the response resonates with the required sentiment.
    * **Audience:** Identifying the intended audience tailors the LLM's response to be targeted to an audience.
    * **Response:** Providing the response format, like text or json, ensures the LLM outputs, and help build pipelines.
* Source: https://library.westpoint.edu/GenAl/prompting

---

## CO-STAR Example Prompt

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_68.png?raw=true)

* **Context:** At UF College of Education, faculty and staff are actively exploring ways to enhance learning experiences by integrating digital learning tools into traditional classroom settings. Recent initiatives have highlighted the need for innovative strategies to engage students and improve educational outcomes
* **Objective:** Develop a list of actionable and innovative strategies that blend digital learning technologies with traditional classroom instruction to boost student engagement and learning effectiveness.
* **Style:** Compose the response in an academic yet accessible manner, using clear bullet points and concise explanations to ensure the ideas are easy for busy educators to review and implement.
* **Tone:** Maintain a supportive and motivational tone that acknowledges the challenges of integrating new technologies while encouraging proactive experimentation and collaboration.
* **Audience:** The response should be directed to UF College of Education faculty and staff, particularly those involved in curriculum development and educational technology integration.
* **Response:** Please provide a detailed list of strategies complete with actionable steps, supporting examples, and, where applicable, references to case studies or best practices from similar educational institutions.
* Source: https://library.westpoint.edu/GenAl/prompting

---

## CO-STAR Example Output in NaviGator Chat

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_69.png?raw=true)

* Example output from NaviGator Chat (03-mini model) based on the CO-STAR prompt.
* **Strategies provided:**
    * **Flipped Classroom Model:**
        * Action Steps: Record video lectures, assign pre-class activities. Use class time for active learning.
        * Supporting Example: Flipped Learning Network studies show increased engagement.
        * Best Practice: Integrate platforms like Panopto or Kaltura.
    * **Interactive Digital Platforms for In-Class Participation:**
        * Action Steps: Incorporate real-time polling (Kahoot, PollEverywhere). Use interactive whiteboards (Google Jamboard, Microsoft Whiteboard).
        * Supporting Example: Case study showed 40% increase in participation.
        * Best Practice: Embed short interactive segments.
    * **Blended Learning Strategies for Differentiated Instruction:**
        * Action Steps: Combine online/offline resources. Develop modular content.
        * Supporting Example: Research shows improved performance with multiple modalities.
        * Best Practice: Manage content in LMS (Canvas, Blackboard).

---

## Thank You & Contact

![](https://github.com/jayrosen-design/UF-AI-Edu-Fair/blob/main/slides/UF%20Edu%20AI%20Fair%20-%20AI%20%26%20AR%20in%20the%20Classroom%20(Jay%20Rosen%2C%20UF%20COE)_Page_70.png?raw=true)

* AR Expeditions {newworldsreading}
* Partners: EQUITABLE LEARNING TECHNOLOGY LAB, E-Learning, Technology and Communications, PK Yonge Developmental Research School, UF COLLEGE OF EDUCATION, UF Lastinger Center for Learning
* So, while AR may have started with catching Pokémon or the occasional Zoom filter mishap, today, we’re using it to catch something even more important for kids’ attention and excitement for reading.
* We’re thrilled about the impact AR Expeditions is having, and we’d love you to see it in action. If you’d like to learn more or experience our app firsthand, we invite you to visit our tables during lunch. Our team and the New Worlds Reading team will be there to answer questions, walk you through the technology, and let you try it out for yourself.
* We truly appreciate your support as we continue developing new ways to make reading more engaging and accessible for students.
* Thank you again and Go Gators!
